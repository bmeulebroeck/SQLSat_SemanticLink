{"cells":[{"cell_type":"markdown","source":["## **Exploring Semantic Link**\n","Notebook with examples and explanations for basic functions using Semantic Link\n","<br> First step: Select 'Lakehouses' on the left, 'Remove All Lakehouses', then add a Lakehouse you have access to or create a new one.\n","<br><br>[Documentation and tutorials](https://learn.microsoft.com/en-us/fabric/data-science/semantic-link-overview)\n","<br><br>[Detailed SemPy Function listing](https://learn.microsoft.com/en-us/python/api/semantic-link-sempy/sempy.fabric?view=semantic-link-python)"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a7f06687-9e28-462f-852c-cc6fa812bc9f"},{"cell_type":"code","source":["# Import the SemanticLink package and other dependencies\n","# SemanticLink is included in the default environment starting the with the Spark3.4 env, no need to pip install any more\n","import sempy.fabric as fabric\n","import pandas as pd\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"95ed342d-639e-4d6c-8fa7-64e8025b50d6"},{"cell_type":"code","source":["# The dir command will retrieve a list of functions available\n","dir(fabric)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4182a29f-e60b-44ca-b5d7-198b6bdb38e9"},{"cell_type":"code","source":["# There is a handy help function built-in as well. Use the syntax 'help(fabric.[function name from above])\n","help(fabric.refresh_dataset)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4e617784-fbb6-4c10-ae64-b99983ae84aa"},{"cell_type":"markdown","source":["### List functions - gather information on semantic model elements\n","Using the 'List' functions you can quickly compile information about your semantic models."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"75fd960d-4dc0-4e00-b24c-b608897543e7"},{"cell_type":"code","source":["# fabric.list_capacities()\n","fabric.list_datasets()\n","# fabric.list_workspaces()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f2248072-5eda-49b7-a52a-8cd2e1b89f8c"},{"cell_type":"code","source":["# List all tables in the specified data model\n","tables_df = fabric.list_tables(\"NW_Custom_Dataset\",extended=True)\n","display(tables_df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"870dc5db-e522-4317-a9c5-6beb69957f29"},{"cell_type":"code","source":["# Prep for writing back to LH table - remove spaces in column names, add the semantic model name\n","tables_df.columns = tables_df.columns.str.replace(' ','')\n","tables_df['SemanticModelName'] = \"NW_Custom_Dataset\"\n","tables_df"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7efe3439-8407-4fb3-8a61-6547376bd309"},{"cell_type":"code","source":["# List all columns in the specified data model\n","columns_df = fabric.list_columns(\"NW_Custom_Dataset\",extended=True)\n","display(columns_df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"6237a4af-9e31-43e7-b7cf-2c1be791d1b0"},{"cell_type":"code","source":["# Prep for writing back to LH table - remove spaces in column names, add the semantic model name\n","columns_df.columns = columns_df.columns.str.replace(' ','')\n","columns_df['SemanticModelName'] = \"NW_Custom_Dataset\"\n","columns_df"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"56b603d8-5164-4361-810d-4c9c7b3cdfdf"},{"cell_type":"code","source":["# List all measures in the specified data model\n","measures_df = fabric.list_measures(\"NW_Custom_Dataset\")\n","display(measures_df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"74180ed9-d15d-4416-87e7-d22052119cb8"},{"cell_type":"code","source":["# Prep for writing back to LH table - remove spaces in column names, add the semantic model name\n","measures_df.columns = measures_df.columns.str.replace(' ','')\n","measures_df['SemanticModelName'] = \"NW_Custom_Dataset\"\n","measures_df"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a8784e61-3125-4954-b519-f4d5affa5540"},{"cell_type":"markdown","source":["#### All this can be easily written back to tables in the LH to build out a semantic model/data dictionary as documentation:"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5936eafd-5fd2-4231-bdf0-c1eedbbf7407"},{"cell_type":"code","source":["# I've had the best luck converting the pandas df to a spark df before writing to the LH. Using overwrite in this scenario, but you could also append (with a timestamp)\n","spark.createDataFrame(tables_df).write.mode('overwrite').option(\"mergeSchema\", \"true\").saveAsTable(\"ModelTables\")\n","spark.createDataFrame(columns_df).write.mode('overwrite').option(\"mergeSchema\", \"true\").saveAsTable(\"ModelColumns\")\n","spark.createDataFrame(measures_df).write.mode('overwrite').option(\"mergeSchema\", \"true\").saveAsTable(\"ModelMeasures\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"613e44b8-f408-47d2-b02f-d488cdf669e8"},{"cell_type":"markdown","source":["#### We can also take a look at relationship information"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2b00b88d-ea9f-42d0-8a27-ac3f840b66ad"},{"cell_type":"code","source":["from sempy.relationships import plot_relationship_metadata\n","from sempy.relationships import find_relationships\n","from sempy.fabric import list_relationship_violations\n","from sempy.dependencies import plot_dependency_metadata"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"648aff91-10e2-4dd1-b4f0-5c1f8975ba3e"},{"cell_type":"code","source":["help(find_relationships)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6c7c07ad-9119-49d9-9f70-a0641b4e9546"},{"cell_type":"code","source":["# List all relationships\n","relationships_df = fabric.list_relationships(\"NW_Custom_Dataset\")\n","relationships_df"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0482452f-8c03-4bbb-8612-a4add4f057da"},{"cell_type":"code","source":["# Visually plot relationships\n","plot_relationship_metadata(relationships_df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b03883ca-43de-472a-9cea-0d715904351f"},{"cell_type":"markdown","source":["### Extract data from the model\n","There are several ways to access the model data, either using the business logic built-in via measures or DAX, or by querying the model directly"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"de936049-6c0a-437c-81e2-5f7b2a9b100b"},{"cell_type":"code","source":["# Evaluate a measure from a dataset. Dataset, Measure, GroupBy column(s)\n","invoices_msr_df = (\n","    fabric.evaluate_measure(\n","        \"NW_Custom_Dataset\",\n","        \"TotalInvoicedSales\",\n","        groupby_columns=[\"NW_Invoices[ProductName]\"]\n","        )\n",")\n","invoices_msr_df = invoices_msr_df.sort_values([\"TotalInvoicedSales\"],ascending=False)\n","\n","display(invoices_msr_df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"f8b448c8-1850-4090-ab16-80d434971e9c"},{"cell_type":"code","source":["# Evaluate DAX directly\n","dax_example_df = fabric.evaluate_dax(dataset=\"NW_Custom_Dataset\",\n","    dax_string=\n","    \"\"\"\n","    EVALUATE \n","    SUMMARIZECOLUMNS(\n","        'NW_Invoices'[ProductName],\n","        \"TotalInvoicedSales\", 'NW_Invoices'[TotalInvoicedSales]\n","    )\"\"\"\n",")\n","dax_example_df = dax_example_df.sort_values([\"[TotalInvoicedSales]\"],ascending=False)\n","display(dax_example_df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"7bbdade1-bcea-4586-8360-f09df52aa571"},{"cell_type":"code","source":["# Direct Query an attached Lakehouse (Update the Lakehouse in the table signifiers)\n","from pyspark.sql.functions import month, year, col, desc, asc\n","invoices_df = spark.sql(\"SELECT * FROM SixthGreatLake.NW_Invoices\")\n","# display(invoices_df)\n","\n","# Aggregate Invoices to a Monthly Level\n","invoices_agg_df = invoices_df.withColumn(\"ProductName\",invoices_df.ProductName)\\\n",".groupBy(\"ProductName\")\\\n",".sum(\"ExtendedPrice\")\\\n","# .orderBy(\"ExtendedPrice\")\n","invoices_agg_df.sort(desc(\"sum(ExtendedPrice)\")).show()\n","# display(invoices_agg_df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"49d14dba-6677-4b46-9ddc-a4b568a76e11"},{"cell_type":"markdown","source":["### Data Science: Time-series forecasting with Prophet\n","Now let's grab some data and run a forecast"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c13428f0-36fe-4c3b-8e33-3b71351094f8"},{"cell_type":"code","source":["# Direct Query an attached Lakehouse (Update the Lakehouse in the table signifiers)\n","from pyspark.sql.functions import month, year, col\n","invoices_df = spark.sql(\"SELECT * FROM SixthGreatLake.NW_Invoices JOIN SixthGreatLake.NW_Orders ON SixthGreatLake.NW_Invoices.OrderID = SixthGreatLake.NW_Orders.OrderID\")\n","\n","# Aggregate Invoices to a Monthly Level\n","invoices_agg_df = invoices_df.withColumn(\"Month\", month(\"OrderDate\"))\\\n",".withColumn(\"Year\",year(\"OrderDate\"))\\\n",".groupBy(\"Year\",\"Month\")\\\n",".sum(\"ExtendedPrice\")\\\n",".orderBy(\"Year\",\"Month\")\n","\n","display(invoices_agg_df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"057ad767-1a35-4a8b-b96d-fd1dbfc46f57"},{"cell_type":"code","source":["# Convert to Pandas df and drop last value (incomplete month)\n","invoices_agg_dfpd = invoices_agg_df.toPandas()\n","invoices_final_df = invoices_agg_dfpd.drop(22)\n","invoices_final_df"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"5d88dc62-c54c-4099-a90d-9b1ead458d45"},{"cell_type":"markdown","source":["Now let's use the open-source time series forecasting tool Prophet to run a forecast\n","<br><br>[Prophet info](https://pypi.org/project/prophet/)"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"c0c4852c-eda9-4993-ae79-d5ae079a19ab"},{"cell_type":"code","source":["!pip install prophet\n","\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import month, year, col\n","from prophet import Prophet\n","\n","# Initialize Spark session\n","spark = SparkSession.builder.appName(\"Prophet Forecasting\").getOrCreate()\n","\n","# Prepare the data for Prophet\n","invoices_final_df['ds'] = pd.to_datetime(invoices_final_df[['Year', 'Month']].assign(DAY=1))\n","invoices_final_df['y'] = invoices_final_df['sum(ExtendedPrice)']\n","\n","# Fit the Prophet model\n","model = Prophet(yearly_seasonality=True, weekly_seasonality=False,daily_seasonality=False)\n","model.fit(invoices_final_df[['ds', 'y']])\n","\n","# Create a DataFrame for future predictions (e.g., next 12 months)\n","future = model.make_future_dataframe(periods=12, freq='M')\n","\n","# Forecast\n","forecast = model.predict(future)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4314a5c2-2444-4934-b550-5c375152f3ea"},{"cell_type":"code","source":["# Plot the forecast from the previous step\n","model.plot(forecast);\n","model.plot_components(forecast);"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"072e7dbb-f137-4416-ab4a-e36805fa676d"},{"cell_type":"markdown","source":["### Access the REST APIs quickly and easily\n","No need to worry about authentication, scopes, etc. A user running a notebook can access whatever endpoints are available based on their role permissions\n","<br><br>[Power BI REST API Docs](https://learn.microsoft.com/en-us/rest/api/power-bi/)\n","<br><br>[Fabric REST API Docs](https://learn.microsoft.com/en-us/rest/api/fabric/articles/)"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"575f0ef5-68d6-499b-97e1-2c70c3c7a3f8"},{"cell_type":"code","source":["import json \n","\n","# Initialize the PowerBI REST client\n","client = fabric.PowerBIRestClient()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"789ba861-f3ae-4aa6-9581-8311a819ea12"},{"cell_type":"code","source":["# Make a 'GET' request to the selected endpoint. Notebook user must have permissions to make API request\n","response = client.get('v1.0/myorg/groups/baa7413d-7c02-4a2c-b8c3-e8ec3fec2ddc/datasets')\n","response"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f0844d47-6f33-4181-8148-a5655c73dae2"},{"cell_type":"code","source":["# Parse the response and normalize to a dataframe\n","data = json.loads(response.text)\n","datasets_df = pd.json_normalize(data['value'])\n","display(datasets_df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"80b3aa93-09b6-432e-9acf-c34beec1f01a"},{"cell_type":"code","source":["# Initialize the Fabric REST Client\n","client_fab = fabric.FabricRestClient()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5757e58e-232f-4ab9-a1d0-dab359054767"},{"cell_type":"code","source":["# Make a 'GET' request to the selected endpoint. Notebook user must have permissions to make API request\n","response = client_fab.get('v1/workspaces/baa7413d-7c02-4a2c-b8c3-e8ec3fec2ddc/items')\n","response"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"de01ba7e-bfa8-4034-9673-628c279fe36c"},{"cell_type":"code","source":["# Parse the response and normalize to a dataframe\n","data = json.loads(response.text)\n","fabitems_df = pd.json_normalize(data['value'])\n","display(fabitems_df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"827d9bb0-af96-4a5d-bf49-85843889f966"},{"cell_type":"markdown","source":["### Can also use other Python libraries\n","Such as powerbiclient to show a report in your notebook"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1d3a5df9-4952-4270-b1d5-781e1710ff81"},{"cell_type":"code","source":["# Use the PowerBIRESTClient to display a report\n","reports_df = fabric.list_reports()\n","# reports_df # Show the list of reports\n","report_name = \"BC_Prices\"\n","report_id = reports_df[reports_df['Name'] == report_name]['Id'].iloc[0]\n","# report_id # show the report id selected"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"35fc928f-e1f1-4361-8a82-90f4d4ea67dc"},{"cell_type":"code","source":["from powerbiclient import Report\n","report = Report(group_id=None, report_id=report_id)\n","report"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b2d5fb9f-6c4a-40c7-8c1e-e8cd3a9b13ff"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{"default_lakehouse":"8c2e91a8-9fff-40c6-b5f0-44eb99382455","default_lakehouse_name":"SixthGreatLake","default_lakehouse_workspace_id":"baa7413d-7c02-4a2c-b8c3-e8ec3fec2ddc","known_lakehouses":[{"id":"8c2e91a8-9fff-40c6-b5f0-44eb99382455"},{"id":"0a0b898e-fd38-43a1-b6be-7b6285ea875d"}]}}},"nbformat":4,"nbformat_minor":5}